{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRAILS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUQN78QgKZZkcP2E+AfdPf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/romoreira/distributed_learning/blob/master/TRAILS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orW1Ov-AOY39",
        "outputId": "09f4cdf2-e3dc-42f5-cd71-7ca32756d5c9"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FB1xEdt5PCw2",
        "outputId": "12ed7402-6f93-465c-d3ac-6d439c138162"
      },
      "source": [
        "import os\n",
        "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.backend import image_data_format\n",
        "\n",
        "import logging\n",
        "import threading\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import copy\n",
        "import random\n",
        "import sys\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "import sys\n",
        "sys.path.append('/content/gdrive/MyDrive/Colab Notebooks')\n",
        "\n",
        "from build_model import Model\n",
        "import csv\n",
        "\n",
        "# client config\n",
        "NUMOFCLIENTS = 2 # number of client(as particles)\n",
        "SELECT_CLIENTS = 0.5 # c\n",
        "EPOCHS = 1 # number of total iteration\n",
        "CLIENT_EPOCHS = 5 # number of each client's iteration\n",
        "BATCH_SIZE = 10 # Size of batches to train on\n",
        "DROP_RATE = 0\n",
        "\n",
        "#lists of federated_clients\n",
        "federated_clients_as_threads = []\n",
        "\n",
        "# model config \n",
        "LOSS = 'categorical_crossentropy' # Loss function\n",
        "NUMOFCLASSES = 10 # Number of classes\n",
        "lr = 0.0025\n",
        "# OPTIMIZER = SGD(lr=0.015, decay=0.01, nesterov=False)\n",
        "OPTIMIZER = SGD(lr=lr, momentum=0.9, decay=lr/(EPOCHS*CLIENT_EPOCHS), nesterov=False) # lr = 0.015, 67 ~ 69%\n",
        "\n",
        "def utf8len(s):\n",
        "    return len(s.encode('utf-8'))\n",
        "\n",
        "def write_csv(method_name, list):\n",
        "    file_name = '{name}_CIFAR10_randomDrop_{drop}%_output_C_{c}_LR_{lr}_CLI_{cli}_CLI_EPOCHS_{cli_epoch}_TOTAL_EPOCHS_{epochs}_BATCH_{batch}.csv'\n",
        "    file_name = file_name.format(folder=\"origin_drop\",drop=DROP_RATE, name=method_name, c=SELECT_CLIENTS, lr=lr, cli=NUMOFCLIENTS, cli_epoch=CLIENT_EPOCHS, epochs=EPOCHS, batch=BATCH_SIZE)\n",
        "\n",
        "    save_path = \"/content/gdrive/MyDrive/Colab Notebooks\"\n",
        "    completeName = os.path.join(save_path, file_name)\n",
        "\n",
        "    f = open(completeName, 'w', encoding='utf-8', newline='')\n",
        "    wr = csv.writer(f)\n",
        "    \n",
        "    \n",
        "\n",
        "    for l in list:\n",
        "        wr.writerow(l)\n",
        "    \n",
        "    f.close()\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    # Code for experimenting with CIFAR-10 datasets.\n",
        "    (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "    \n",
        "    # Code for experimenting with MNIST datasets.\n",
        "    # (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "    # X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "    # X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "    \n",
        "    X_train = X_train.astype('float32')\n",
        "    X_test = X_test.astype('float32')\n",
        "    X_train = X_train / 255.0\n",
        "    X_test = X_test / 255.0\n",
        "\n",
        "    Y_train = to_categorical(Y_train)\n",
        "    Y_test = to_categorical(Y_test)\n",
        "\n",
        "    return (X_train, Y_train), (X_test, Y_test)\n",
        "\n",
        "\n",
        "def init_model(train_data_shape):\n",
        "    print(\"Data Shape: \"+str(train_data_shape))\n",
        "    model = Model(loss=LOSS, optimizer=OPTIMIZER, classes=NUMOFCLASSES)\n",
        "    fl_model = model.fl_paper_model(train_shape=train_data_shape)\n",
        "\n",
        "    return fl_model\n",
        "\n",
        "\n",
        "def client_data_config(x_train, y_train):\n",
        "    client_data = [() for _ in range(NUMOFCLIENTS)] # () for _ in range(NUMOFCLIENTS)\n",
        "    num_of_each_dataset = int(x_train.shape[0] / NUMOFCLIENTS)\n",
        "\n",
        "    print(\"Size of x_train: \"+str(len(x_train)))\n",
        "\n",
        "    print(\"Num_of_each_dataset: \"+str(num_of_each_dataset))\n",
        "    \n",
        "    for i in range(NUMOFCLIENTS):\n",
        "        split_data_index = []\n",
        "        while len(split_data_index) < num_of_each_dataset:\n",
        "            item = random.choice(range(x_train.shape[0]))\n",
        "            if item not in split_data_index:\n",
        "                split_data_index.append(item)\n",
        "        \n",
        "        new_x_train = np.asarray([x_train[k] for k in split_data_index])\n",
        "        new_y_train = np.asarray([y_train[k] for k in split_data_index])\n",
        "    \n",
        "        client_data[i] = (new_x_train, new_y_train)\n",
        "\n",
        "    return client_data\n",
        "\n",
        "\n",
        "def fedAVG(server_weight):\n",
        "    #print(\"Server_weight[0]): \"+str(server_weight[0]))\n",
        "    avg_weight = np.array(server_weight[0])\n",
        "    print(\"len(Server_weight[0]): \"+str(len(server_weight)))\n",
        "\n",
        "    if len(server_weight) > 1:\n",
        "        for i in range(1, len(server_weight)):\n",
        "            print(\"Each i of server_weight: \"+str(server_weight[i]))\n",
        "            avg_weight += server_weight[i]\n",
        "    \n",
        "    avg_weight = avg_weight / len(server_weight)\n",
        "\n",
        "    return avg_weight\n",
        "\n",
        "\n",
        "def client_update(index, client, avg_weight, x_test, y_test):\n",
        "    print(\"Fed_Client Thread {}/{} fitting\\n\".format(index + 1, int(NUMOFCLIENTS * SELECT_CLIENTS)))\n",
        "\n",
        "    \n",
        "    client.fit(client_data[index][0], client_data[index][1],\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        verbose=1,\n",
        "        validation_split=0.2,\n",
        "    )\n",
        "\n",
        "    print(\"\\n\\n\\nEnd of training Thread: \"+str(index))\n",
        "    print(\"\\n\\n\\n Validating the client training: \"+str(index))\n",
        "    scores = fed_client_evaluation(client, x_test, y_test)\n",
        "    print(\"\\n\\nThe accuracy of Client \"+str(index)+\" is: \"+str(scores)+\" \\n\\n\\n\\n\")\n",
        "    send_model_to_server(scores, index)\n",
        "\n",
        "def fed_client_evaluation(model, x_test, y_test):\n",
        "    return model.evaluate(x_test, y_test, batch_size=BATCH_SIZE, verbose=1)\n",
        "\n",
        "\n",
        "def send_model_to_server(metric_scores, client_index):\n",
        "    federated_clients_as_threads[client_index].append(metric_scores)\n",
        "\n",
        "def waiter():\n",
        "    while(True):\n",
        "        print(\"\\n\\n\\n\\nCurrent Status of Federated Client Set: \"+str(federated_clients_as_threads))\n",
        "        time.sleep(10)\n",
        "\n",
        "\n",
        "def fed_client_selection(policy):\n",
        "\n",
        "    if policy == \"TRAILS\":\n",
        "        print(\"Decidir qual cliente escolher\")\n",
        "        #https://github.com/dnanhkhoa/simple-bloom-filter\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    (x_train, y_train), (x_test, y_test) = load_dataset()\n",
        "\n",
        "    federated_clients_as_threads = []\n",
        "\n",
        "    server_model = init_model(train_data_shape=x_train.shape[1:])\n",
        "    server_model.summary()\n",
        "\n",
        "    client_data = client_data_config(x_train, y_train)\n",
        "    print(\"Client_data: \"+str(len(client_data)))\n",
        "    fl_models = []\n",
        "    for i in range(NUMOFCLIENTS):\n",
        "        fl_models.append(init_model(train_data_shape=client_data[i][0].shape[1:]))\n",
        "\n",
        "\n",
        "    avg_weight = np.zeros_like(server_model.get_weights())\n",
        "    print(\"AVG_Weight: \"+str(avg_weight))\n",
        "    server_evaluate_acc = []\n",
        "\n",
        "    print(\"NUMOFCLIENTS: \"+str(NUMOFCLIENTS))\n",
        "    print(\"Select_clients: \"+str(SELECT_CLIENTS))\n",
        "\n",
        "\n",
        "    waiter = threading.Thread(target=waiter, args=(), daemon=True)\n",
        "    waiter.start()\n",
        "    \n",
        "      \n",
        "    for index, client in enumerate(fl_models):\n",
        "   \n",
        "      #print(\"Index: \"+str(index))\n",
        "      #print(\"CLIENT: \"+str(client))\n",
        "      fed = []\n",
        "      a = threading.Thread(target=client_update, args=(index, client, avg_weight, x_test, y_test,))\n",
        "      fed.append(a)\n",
        "      fed.append(index)\n",
        "      fed.append(EPOCHS)\n",
        "\n",
        "      federated_clients_as_threads.append(fed)\n",
        "      #print(federated_clients_as_threads)\n",
        "      #print(\"Client \"+str(index)+\" is inside list and ready to train: \"+str(federated_clients_as_threads[index][0]))\n",
        " \n",
        "#            recv_model = client_update(index, client, epoch, avg_weight)\n",
        "#            evaluation = fed_client_evaluation(recv_model)\n",
        "#            fed_client_selection(evaluation)\n",
        "#\n",
        "#            print(\"Tamanho do RECV_MODEL: \"+str(utf8len(str(recv_model))))\n",
        "#            \n",
        "#            rand = random.randint(0,99)\n",
        "#            drop_communication = range(DROP_RATE)\n",
        "#            if rand not in drop_communication:\n",
        "#                server_weight.append(copy.deepcopy(recv_model.get_weights()))\n",
        "#        \n",
        "#        avg_weight = fedAVG(server_weight)\n",
        "\n",
        "        #print(\"avg_weight: \"+str(avg_weight))\n",
        "\n",
        "\n",
        "#        server_model.set_weights(avg_weight)\n",
        "#        print(\"server {}/{} evaluate\".format(epoch + 1, EPOCHS))\n",
        "#        server_evaluate_acc.append(server_model.evaluate(x_test, y_test, batch_size=BATCH_SIZE, verbose=1))\n",
        "\n",
        "    #for i in range(len(federated_clients_as_threads)):\n",
        "    #    print(\"IIIII: \"+str(i))\n",
        "    #    federated_clients_as_threads[i][0].start()\n",
        "\n",
        "    for i in range(len(federated_clients_as_threads)):\n",
        "        federated_clients_as_threads[i][0].start()\n",
        "\n",
        "    waiter.join()\n",
        "    print(federated_clients_as_threads)\n",
        "    for i in range(len(federated_clients_as_threads)):\n",
        "        federated_clients_as_threads[i][0].join()\n",
        "    \n",
        "\n",
        "#    write_csv(\"FedAvg\", server_evaluate_acc)\n",
        "      \n",
        "    \n",
        "  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape: (32, 32, 3)\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        2432      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        25632     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        51264     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        102464    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4096)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               2097664   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,284,586\n",
            "Trainable params: 2,284,586\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Size of x_train: 50000\n",
            "Num_of_each_dataset: 25000\n",
            "Client_data: 2\n",
            "Data Shape: (32, 32, 3)\n",
            "Data Shape: (32, 32, 3)\n",
            "AVG_Weight: [0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "NUMOFCLIENTS: 2\n",
            "Select_clients: 0.5\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: []\n",
            "Fed_Client Thread 1/1 fitting\n",
            "Fed_Client Thread 2/1 fitting\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 262/2000 [==>...........................] - ETA: 38s - loss: 11.6709 - accuracy: 0.1603\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, started 140533439444736)>, 0, 1], [<Thread(Thread-13, started 140533431052032)>, 1, 1]]\n",
            " 714/2000 [=========>....................] - ETA: 28s - loss: 10.1372 - accuracy: 0.2164\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, started 140533439444736)>, 0, 1], [<Thread(Thread-13, started 140533431052032)>, 1, 1]]\n",
            "1147/2000 [================>.............] - ETA: 19s - loss: 9.1554 - accuracy: 0.2337\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, started 140533439444736)>, 0, 1], [<Thread(Thread-13, started 140533431052032)>, 1, 1]]\n",
            "1596/2000 [======================>.......] - ETA: 9s - loss: 8.3733 - accuracy: 0.2608\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, started 140533439444736)>, 0, 1], [<Thread(Thread-13, started 140533431052032)>, 1, 1]]\n",
            "2000/2000 [==============================] - ETA: 0s - loss: 7.8208 - accuracy: 0.2816\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, started 140533439444736)>, 0, 1], [<Thread(Thread-13, started 140533431052032)>, 1, 1]]\n",
            "2000/2000 [==============================] - 53s 25ms/step - loss: 7.7855 - accuracy: 0.2918 - val_loss: 5.3123 - val_accuracy: 0.3526\n",
            "2000/2000 [==============================] - 54s 25ms/step - loss: 7.8208 - accuracy: 0.2816 - val_loss: 5.3450 - val_accuracy: 0.3784\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, started 140533439444736)>, 0, 1], [<Thread(Thread-13, started 140533431052032)>, 1, 1]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, started 140533439444736)>, 0, 1], [<Thread(Thread-13, started 140533431052032)>, 1, 1]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, started 140533439444736)>, 0, 1], [<Thread(Thread-13, started 140533431052032)>, 1, 1]]\n",
            "\n",
            "\n",
            "\n",
            "End of training Thread: 0\n",
            "\n",
            "\n",
            "\n",
            " Validating the client training: 0\n",
            "\n",
            "\n",
            "\n",
            "End of training Thread: 1\n",
            "\n",
            "\n",
            "\n",
            " Validating the client training: 1\n",
            " 415/1000 [===========>..................] - ETA: 7s - loss: 5.2990 - accuracy: 0.3672\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, started 140533439444736)>, 0, 1], [<Thread(Thread-13, started 140533431052032)>, 1, 1]]\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 5.2980 - accuracy: 0.3621\n",
            " 998/1000 [============================>.] - ETA: 0s - loss: 5.3501 - accuracy: 0.3689\n",
            "\n",
            "The accuracy of Client 1 is: [5.297974586486816, 0.3621000051498413] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1000/1000 [==============================] - 12s 12ms/step - loss: 5.3503 - accuracy: 0.3688\n",
            "\n",
            "\n",
            "The accuracy of Client 0 is: [5.350262641906738, 0.36880001425743103] \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, stopped 140533439444736)>, 0, 1, [5.350262641906738, 0.36880001425743103]], [<Thread(Thread-13, stopped 140533431052032)>, 1, 1, [5.297974586486816, 0.3621000051498413]]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, stopped 140533439444736)>, 0, 1, [5.350262641906738, 0.36880001425743103]], [<Thread(Thread-13, stopped 140533431052032)>, 1, 1, [5.297974586486816, 0.3621000051498413]]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, stopped 140533439444736)>, 0, 1, [5.350262641906738, 0.36880001425743103]], [<Thread(Thread-13, stopped 140533431052032)>, 1, 1, [5.297974586486816, 0.3621000051498413]]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, stopped 140533439444736)>, 0, 1, [5.350262641906738, 0.36880001425743103]], [<Thread(Thread-13, stopped 140533431052032)>, 1, 1, [5.297974586486816, 0.3621000051498413]]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, stopped 140533439444736)>, 0, 1, [5.350262641906738, 0.36880001425743103]], [<Thread(Thread-13, stopped 140533431052032)>, 1, 1, [5.297974586486816, 0.3621000051498413]]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, stopped 140533439444736)>, 0, 1, [5.350262641906738, 0.36880001425743103]], [<Thread(Thread-13, stopped 140533431052032)>, 1, 1, [5.297974586486816, 0.3621000051498413]]]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Current Status of Federated Client Set: [[<Thread(Thread-12, stopped 140533439444736)>, 0, 1, [5.350262641906738, 0.36880001425743103]], [<Thread(Thread-13, stopped 140533431052032)>, 1, 1, [5.297974586486816, 0.3621000051498413]]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6cbd8b25be89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfederated_clients_as_threads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederated_clients_as_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfederated_clients_as_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1058\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}